<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Satellite SST outperforms in-situ loggers for coral bleaching prediction</title>
  <style>
    /* Default styles provided by pandoc.
    ** See https://pandoc.org/MANUAL.html#variables-for-html for config info.
    */
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    /* The extra [class] is a hack that increases specificity enough to
       override a similar rule in reveal.js */
    ul.task-list[class]{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      font-size: inherit;
      width: 0.8em;
      margin: 0 0.8em 0.2em -1.6em;
      vertical-align: middle;
    }
    .display.math{display: block; text-align: center; margin: 0.5rem auto;}
  </style>
  <link rel="stylesheet" href="https://cdn.simplecss.org/simple.min.css" />
</head>
<body>
<header id="title-block-header">
<h1 class="title">Satellite SST outperforms in-situ loggers for coral
bleaching prediction</h1>
</header>
<nav id="TOC" role="doc-toc">
<ul>
<li><a
href="#satellite-sea-surface-temperature-outperforms-in-situ-loggers-for-coral-bleaching-prediction-evidence-from-japans-national-monitoring-program"
id="toc-satellite-sea-surface-temperature-outperforms-in-situ-loggers-for-coral-bleaching-prediction-evidence-from-japans-national-monitoring-program">Satellite
sea surface temperature outperforms in-situ loggers for coral bleaching
prediction: Evidence from Japan’s national monitoring program</a>
<ul>
<li><a href="#abstract" id="toc-abstract">Abstract</a></li>
<li><a href="#introduction" id="toc-introduction">1.
Introduction</a></li>
<li><a href="#methods" id="toc-methods">2. Methods</a>
<ul>
<li><a href="#study-sites-and-data-sources"
id="toc-study-sites-and-data-sources">2.1 Study sites and data
sources</a></li>
<li><a href="#thermal-stress-indicators"
id="toc-thermal-stress-indicators">2.2 Thermal stress
indicators</a></li>
<li><a href="#statistical-analysis" id="toc-statistical-analysis">2.3
Statistical analysis</a></li>
</ul></li>
<li><a href="#results" id="toc-results">3. Results</a>
<ul>
<li><a href="#overall-prediction-skill"
id="toc-overall-prediction-skill">3.1 Overall prediction skill</a></li>
<li><a href="#satellite-versus-in-situ-comparison"
id="toc-satellite-versus-in-situ-comparison">3.2 Satellite versus
in-situ comparison</a></li>
<li><a href="#comparison-with-prior-studies"
id="toc-comparison-with-prior-studies">3.3 Comparison with prior
studies</a></li>
</ul></li>
<li><a href="#discussion" id="toc-discussion">4. Discussion</a>
<ul>
<li><a href="#why-does-satellite-outperform-in-situ"
id="toc-why-does-satellite-outperform-in-situ">4.1 Why does satellite
outperform in-situ?</a></li>
<li><a href="#epistemological-caveats"
id="toc-epistemological-caveats">4.2 Epistemological caveats</a></li>
<li><a href="#implications-for-monitoring-program-design"
id="toc-implications-for-monitoring-program-design">4.3 Implications for
monitoring program design</a></li>
<li><a href="#limitations-and-the-value-of-field-monitoring"
id="toc-limitations-and-the-value-of-field-monitoring">4.4 Limitations
and the value of field monitoring</a></li>
</ul></li>
<li><a href="#conclusions" id="toc-conclusions">5. Conclusions</a></li>
<li><a href="#data-availability" id="toc-data-availability">Data
availability</a></li>
<li><a href="#acknowledgments"
id="toc-acknowledgments">Acknowledgments</a></li>
<li><a href="#author-contributions" id="toc-author-contributions">Author
contributions</a></li>
<li><a href="#competing-interests"
id="toc-competing-interests">Competing interests</a></li>
<li><a href="#references" id="toc-references">References</a></li>
<li><a href="#figure-legends" id="toc-figure-legends">Figure
Legends</a></li>
</ul></li>
</ul>
</nav>
<h1
id="satellite-sea-surface-temperature-outperforms-in-situ-loggers-for-coral-bleaching-prediction-evidence-from-japans-national-monitoring-program">Satellite
sea surface temperature outperforms in-situ loggers for coral bleaching
prediction: Evidence from Japan’s national monitoring program</h1>
<p><strong>Hiroki Fukui</strong></p>
<p>Independent researcher, Tokyo, Japan</p>
<p>Correspondence: [contact via marine-obs.org]</p>
<p><strong>Draft v2.1 — 2026-02-02</strong></p>
<hr />
<h2 id="abstract">Abstract</h2>
<p>Accurate prediction of coral bleaching events is critical for reef
management, yet the relative performance of satellite versus in-situ
temperature measurements for this purpose remains poorly characterized.
Using Japan’s national coral reef monitoring program (Monitoring Sites
1000), we compared the bleaching prediction skill of NOAA CoralTemp
satellite SST against in-situ temperature loggers across 44 sites over
five years (2020–2024). Applying the weather forecast verification
framework, we found that satellite SST substantially outperformed
in-situ loggers (Equitable Threat Score: 0.99 vs 0.79; AUC: 0.88 vs
0.81). The optimal predictor was simply the number of days with SST
≥30°C, with a threshold of 5 days achieving maximum skill. This
counterintuitive result—satellite outperforming in-situ—likely reflects
unstandardized logger deployment depths (−2 to −8 m, undocumented)
introducing heterogeneity into predictions. We emphasize that these
results demonstrate operational predictability within a specific
monitoring framework, not biological truth about thermal stress. Our
findings suggest that (1) absolute temperature thresholds may be
operationally effective for regional bleaching prediction, (2) the
apparent superiority of satellite SST reflects its standardization
rather than physiological relevance, and (3) future monitoring programs
should document logger depths to enable proper validation of satellite
products.</p>
<p><strong>Keywords:</strong> coral bleaching, sea surface temperature,
satellite remote sensing, in-situ monitoring, thermal stress, weather
forecast verification, Japan</p>
<hr />
<h2 id="introduction">1. Introduction</h2>
<p>Mass coral bleaching events have become increasingly frequent
worldwide, with thermal stress recognized as the primary driver (Hughes
et al. 2018). Satellite-derived sea surface temperature (SST) products,
particularly NOAA’s Coral Reef Watch, have become the standard tool for
monitoring thermal stress on coral reefs globally (Liu et al. 2014).
These products calculate Degree Heating Weeks (DHW), which accumulate
thermal anomalies above a climatological baseline to predict bleaching
risk.</p>
<p>However, satellite SST represents bulk temperature of the upper ocean
layer, while corals experience temperatures at specific depths that may
differ substantially from satellite estimates (Wyatt et al. 2023).
In-situ temperature loggers deployed on reefs are often assumed to
provide more accurate measures of the thermal environment experienced by
corals. Yet direct comparisons of satellite versus in-situ temperature
for bleaching prediction remain scarce, particularly in long-term
monitoring contexts.</p>
<p>Japan’s Ministry of Environment operates the Monitoring Sites 1000
(Moni1000) program, which has conducted standardized coral reef surveys
since 2008 across 26 sites spanning from Kushimoto (33°N, the northern
limit of coral reefs in Japan) to Sekisei Lagoon (24°N). A subset of 44
survey locations have co-located temperature loggers, providing a unique
opportunity to directly compare satellite and in-situ temperature as
predictors of observed bleaching.</p>
<p>Here, we apply the weather forecast verification framework proposed
by DeCarlo (2020) to systematically evaluate bleaching prediction skill.
This approach enables objective optimization of prediction thresholds
and direct comparison of different thermal stress indicators. We address
two questions: (1) Does satellite SST or in-situ logger temperature
better predict observed bleaching within this monitoring framework? (2)
What is the optimal thermal threshold for operational bleaching
prediction in Japanese waters?</p>
<hr />
<h2 id="methods">2. Methods</h2>
<h3 id="study-sites-and-data-sources">2.1 Study sites and data
sources</h3>
<p>We analyzed data from 44 survey locations within the Moni1000 program
that had co-located temperature loggers and bleaching observations
during 2020–2024. Sites spanned four regions: Honshu/Kyushu (30–33°N),
Amami Islands (27–28°N), Okinawa Main Island (26–27°N), and Yaeyama
Islands (24–25°N). Bleaching data were obtained from annual visual
surveys conducted by trained divers following standardized protocols.
For each survey location, bleaching presence was defined as any observed
bleaching (&gt;0% of colonies affected).</p>
<p>Satellite SST was obtained from NOAA CoralTemp (5 km resolution,
daily), extracted for the coordinates of each survey location. In-situ
temperature was recorded by loggers deployed at each site, with sampling
intervals ranging from 10 minutes to 1 hour, subsequently aggregated to
daily means. Logger deployment depths ranged from −2 to −8 m according
to program documentation, but specific depths for individual loggers
were not recorded.</p>
<h3 id="thermal-stress-indicators">2.2 Thermal stress indicators</h3>
<p>We calculated the number of days during the summer season
(June–September) when temperature exceeded 30°C, separately for
satellite SST and in-situ loggers. This absolute threshold approach was
chosen based on preliminary analyses showing superior performance
compared to anomaly-based DHW metrics, consistent with Lachs et
al. (2021) who demonstrated the effectiveness of MMM-based (rather than
MMM+1°C) thresholds.</p>
<h3 id="statistical-analysis">2.3 Statistical analysis</h3>
<p>We applied the weather forecast verification framework (DeCarlo 2020)
to evaluate prediction skill. For each threshold of days ≥30°C (1–20
days), we constructed a contingency table of predicted versus observed
bleaching events:</p>
<ul>
<li>Hits (H): Bleaching predicted and observed</li>
<li>False Alarms (FA): Bleaching predicted but not observed</li>
<li>Misses (M): Bleaching not predicted but observed</li>
<li>Correct Negatives (CN): Bleaching not predicted and not
observed</li>
</ul>
<p>From these, we calculated:</p>
<ul>
<li><strong>Equitable Threat Score (ETS)</strong>: ETS = H / (H + FA + M
− H_random), where H_random = (H + FA)(H + M) / n. ETS rewards correct
predictions while accounting for chance, ranging from −1/3 to 1
(perfect).</li>
<li><strong>Bias</strong>: (H + FA) / (H + M). Values &gt;1 indicate
over-prediction, &lt;1 under-prediction.</li>
<li><strong>Probability of Detection (POD)</strong>: H / (H + M).
Equivalent to sensitivity.</li>
<li><strong>False Alarm Ratio (FAR)</strong>: FA / (H + FA).</li>
<li><strong>Area Under the ROC Curve (AUC)</strong>: Calculated across
all thresholds.</li>
</ul>
<p>The optimal threshold was defined as that maximizing ETS, following
standard practice in weather forecast verification.</p>
<hr />
<h2 id="results">3. Results</h2>
<h3 id="overall-prediction-skill">3.1 Overall prediction skill</h3>
<p>A total of 204 site-year observations were available for satellite
SST analysis, of which 182 had paired in-situ logger data. Bleaching was
observed in 76 of 204 observations (37%) for the full dataset and 65 of
182 (36%) for the paired dataset.</p>
<p>For satellite SST (CoralTemp), the optimal threshold was 5 days
≥30°C, achieving ETS = 0.84, POD = 0.74, FAR = 0.24, and Bias = 0.97
(Table 1). AUC was 0.81 for the full dataset.</p>
<p><strong>Table 1. Prediction skill metrics for CoralTemp SST by
threshold (n=204)</strong></p>
<table style="width:100%;">
<colgroup>
<col style="width: 39%" />
<col style="width: 8%" />
<col style="width: 9%" />
<col style="width: 8%" />
<col style="width: 8%" />
<col style="width: 4%" />
<col style="width: 6%" />
<col style="width: 6%" />
<col style="width: 8%" />
</colgroup>
<thead>
<tr>
<th>Threshold (days ≥30°C)</th>
<th>ETS</th>
<th>Bias</th>
<th>POD</th>
<th>FAR</th>
<th>H</th>
<th>FA</th>
<th>M</th>
<th>CN</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0.803</td>
<td>1.18</td>
<td>0.78</td>
<td>0.34</td>
<td>59</td>
<td>31</td>
<td>17</td>
<td>97</td>
</tr>
<tr>
<td>3</td>
<td>0.806</td>
<td>1.13</td>
<td>0.76</td>
<td>0.33</td>
<td>58</td>
<td>28</td>
<td>18</td>
<td>100</td>
</tr>
<tr>
<td><strong>5</strong></td>
<td><strong>0.843</strong></td>
<td><strong>0.97</strong></td>
<td><strong>0.74</strong></td>
<td><strong>0.24</strong></td>
<td><strong>56</strong></td>
<td><strong>18</strong></td>
<td><strong>20</strong></td>
<td><strong>110</strong></td>
</tr>
<tr>
<td>7</td>
<td>0.742</td>
<td>0.87</td>
<td>0.66</td>
<td>0.24</td>
<td>50</td>
<td>16</td>
<td>26</td>
<td>112</td>
</tr>
<tr>
<td>10</td>
<td>0.548</td>
<td>0.66</td>
<td>0.50</td>
<td>0.24</td>
<td>38</td>
<td>12</td>
<td>38</td>
<td>116</td>
</tr>
<tr>
<td>14</td>
<td>0.438</td>
<td>0.54</td>
<td>0.41</td>
<td>0.24</td>
<td>31</td>
<td>10</td>
<td>45</td>
<td>118</td>
</tr>
</tbody>
</table>
<p><em>Notes: ETS = Equitable Threat Score; POD = Probability of
Detection; FAR = False Alarm Ratio. Bold indicates optimal
threshold.</em></p>
<h3 id="satellite-versus-in-situ-comparison">3.2 Satellite versus
in-situ comparison</h3>
<p>When compared on the same 182 observations with both satellite and
logger data, satellite SST substantially outperformed in-situ loggers
across all metrics (Table 2, Figure 1). At the optimal threshold of 5
days, satellite ETS was 0.99 compared to 0.79 for loggers.</p>
<p><strong>Table 2. Comparison of CoralTemp SST and in-situ logger at
5-day threshold (n=182)</strong></p>
<table>
<colgroup>
<col style="width: 23%" />
<col style="width: 9%" />
<col style="width: 9%" />
<col style="width: 9%" />
<col style="width: 9%" />
<col style="width: 10%" />
<col style="width: 5%" />
<col style="width: 7%" />
<col style="width: 7%" />
<col style="width: 9%" />
</colgroup>
<thead>
<tr>
<th>Data source</th>
<th>ETS</th>
<th>AUC</th>
<th>POD</th>
<th>FAR</th>
<th>Bias</th>
<th>H</th>
<th>FA</th>
<th>M</th>
<th>CN</th>
</tr>
</thead>
<tbody>
<tr>
<td>CoralTemp SST</td>
<td>0.990</td>
<td>0.878</td>
<td>0.86</td>
<td>0.24</td>
<td>0.97</td>
<td>56</td>
<td>18</td>
<td>9</td>
<td>99</td>
</tr>
<tr>
<td>In-situ logger</td>
<td>0.791</td>
<td>0.805</td>
<td>0.77</td>
<td>0.33</td>
<td>0.87</td>
<td>50</td>
<td>25</td>
<td>15</td>
<td>92</td>
</tr>
<tr>
<td><strong>Difference</strong></td>
<td><strong>+0.199</strong></td>
<td><strong>+0.073</strong></td>
<td><strong>+0.09</strong></td>
<td><strong>−0.09</strong></td>
<td><strong>+0.10</strong></td>
<td><strong>+6</strong></td>
<td><strong>−7</strong></td>
<td><strong>−6</strong></td>
<td><strong>+7</strong></td>
</tr>
</tbody>
</table>
<p><em>Notes: Comparison performed on 182 site-year observations with
both satellite and logger data. Bleaching observed in 65/182
(36%).</em></p>
<p>The superior satellite performance was driven by fewer false alarms
(18 vs 25) and more hits (56 vs 50) compared to loggers.</p>
<h3 id="comparison-with-prior-studies">3.3 Comparison with prior
studies</h3>
<p>Our maximum ETS of 0.84–0.99 substantially exceeds the global optimum
of 0.218 reported by DeCarlo (2020) using DHW as a predictor across 100
sites worldwide (Table 3). This difference likely reflects the regional
specificity of our model and the use of absolute temperature thresholds
rather than anomaly-based metrics.</p>
<p><strong>Table 3. Comparison with DeCarlo (2020) global
analysis</strong></p>
<table>
<thead>
<tr>
<th>Study</th>
<th>Scope</th>
<th>Indicator</th>
<th>Optimal threshold</th>
<th>Maximum ETS</th>
</tr>
</thead>
<tbody>
<tr>
<td>DeCarlo (2020)</td>
<td>Global, 100 sites</td>
<td>DHW</td>
<td>3.5 °C-weeks</td>
<td>0.218</td>
</tr>
<tr>
<td>This study</td>
<td>Japan, 44 sites</td>
<td>Days ≥30°C</td>
<td>5 days</td>
<td>0.84–0.99</td>
</tr>
</tbody>
</table>
<hr />
<h2 id="discussion">4. Discussion</h2>
<h3 id="why-does-satellite-outperform-in-situ">4.1 Why does satellite
outperform in-situ?</h3>
<p>The counterintuitive finding that satellite SST outperforms in-situ
loggers for bleaching prediction demands explanation. We propose three
non-mutually exclusive hypotheses:</p>
<p><strong>Hypothesis 1: Unstandardized logger depths.</strong> The
Moni1000 program documents logger depths as ranging from −2 to −8 m, but
specific depths for individual loggers are not recorded. Temperature
decreases with depth due to solar heating of surface waters,
particularly during calm summer conditions when bleaching risk is
highest. A logger at −8 m may record substantially lower temperatures
than one at −2 m during the same heat event. This depth variability
introduces heterogeneity into bleaching predictions based on logger
data, while satellite SST consistently measures near-surface
temperature. In such a setting, in-situ loggers do not constitute ground
truth, but an unmodeled mixture of depth-dependent thermal regimes.</p>
<p><strong>Hypothesis 2: Surface heat input as the driver.</strong>
Coral bleaching may be driven more by cumulative heat input from the
surface than by the absolute temperature at coral depth. Satellite SST
directly measures this surface thermal forcing, while subsurface loggers
capture a buffered signal. This interpretation aligns with Skirving et
al. (2019), who emphasized the importance of surface heat flux for
bleaching. However, this hypothesis remains speculative and requires
targeted experimental validation.</p>
<p><strong>Hypothesis 3: Spatial averaging.</strong> Satellite SST
represents a 5 km spatial average, potentially providing a more
representative measure of regional thermal stress than point
measurements from individual loggers. Micro-scale variability in logger
temperatures may not correlate with reef-wide bleaching patterns.</p>
<h3 id="epistemological-caveats">4.2 Epistemological caveats</h3>
<p>We emphasize that this study evaluates operational predictability
under real-world monitoring constraints, not biological truth about
thermal stress thresholds. Bleaching observations in Moni1000 are
institutionally mediated outcomes—annual, visual, binary—that may not
directly reflect the cumulative physiological damage corals experience.
The apparent superiority of satellite SST thus reflects its stability
and standardization as a predictor within this specific observational
framework, not necessarily its physiological relevance.</p>
<p>The exceptionally high skill scores (ETS up to 0.99) warrant
particular caution. These values were obtained by threshold optimization
on the same dataset used for evaluation, without cross-validation or
out-of-sample testing. We therefore present these results as evidence of
strong association within this dataset rather than validated predictive
skill for future events. Prospective testing of the 5-day threshold on
independent data remains essential before operational deployment.</p>
<h3 id="implications-for-monitoring-program-design">4.3 Implications for
monitoring program design</h3>
<p>Our results have practical implications for coral reef monitoring
programs. First, the lack of documented logger depths in Moni1000—a
well-resourced national program—suggests this issue may be widespread.
We recommend that monitoring programs either (1) standardize logger
deployment at a fixed depth (e.g., −3 m), or (2) explicitly record
deployment depth for each logger to enable depth-stratified
analyses.</p>
<p>Second, for operational early warning purposes, a simple threshold of
“≥5 days above 30°C” could provide reef managers with an actionable
alert requiring minimal computational resources. When CoralTemp SST
exceeds 30°C for 5 consecutive days during summer, managers could
initiate surveillance dives or prepare intervention measures.</p>
<h3 id="limitations-and-the-value-of-field-monitoring">4.4 Limitations
and the value of field monitoring</h3>
<p>Several limitations should be noted. First, our analysis covers only
five years (2020–2024), a period that included both non-bleaching years
(2021) and severe bleaching years (2022, 2024). Longer time series would
enable more robust threshold validation. Second, we analyzed
presence/absence of bleaching without considering severity. Third, our
results are specific to Japanese reefs spanning 24–33°N and may not
generalize to tropical reef systems with different thermal regimes.</p>
<p>Critically, our finding should not be interpreted as an argument
against field monitoring. In-situ measurements remain essential for
understanding depth-dependent thermal regimes, light environments, water
flow, and local stressors that satellites cannot capture. The value of
in-situ data for mechanistic understanding is not diminished by its
reduced predictive skill in this operational context. Rather, we suggest
that the current monitoring design—with undocumented logger
depths—inadvertently undermines the validation role that in-situ data
are intended to serve.</p>
<hr />
<h2 id="conclusions">5. Conclusions</h2>
<p>Using Japan’s national coral reef monitoring data, we demonstrate
that satellite SST shows stronger association with observed bleaching
events than in-situ temperature loggers within this monitoring
framework. This counterintuitive result likely reflects unstandardized
logger deployment depths, highlighting an often-overlooked issue in
coral reef monitoring design. We recommend that monitoring programs
standardize or document logger depths, and suggest that simple absolute
temperature thresholds (days ≥30°C) may provide operationally effective
bleaching prediction for management applications—while recognizing that
operational utility should not be conflated with biological truth.</p>
<hr />
<h2 id="data-availability">Data availability</h2>
<p>Moni1000 data were provided by the Biodiversity Center of Japan,
Ministry of Environment (approval no. 環生多発第2601271号). Satellite
SST data are publicly available from NOAA Coral Reef Watch.</p>
<h2 id="acknowledgments">Acknowledgments</h2>
<p>We thank the Ministry of Environment and the Biodiversity Center of
Japan for providing Moni1000 data and for their sustained commitment to
coral reef monitoring in Japan. This work was conducted independently
without external funding.</p>
<h2 id="author-contributions">Author contributions</h2>
<p>HF conceived the study, analyzed data, and wrote the manuscript.</p>
<h2 id="competing-interests">Competing interests</h2>
<p>The author declares no competing interests.</p>
<hr />
<h2 id="references">References</h2>
<p>DeCarlo TM (2020) Treating coral bleaching as weather: a framework to
validate and optimize prediction skill. PeerJ 8:e9449.</p>
<p>Hughes TP, Kerry JT, Baird AH, et al. (2018) Global warming
transforms coral reef assemblages. Nature 556:492–496.</p>
<p>Lachs L, Skirving WJ, et al. (2021) Emergent increase in coral
thermal tolerance reduces mass bleaching under climate change. Nature
Communications 12:1–12.</p>
<p>Liu G, Heron SF, Eakin CM, et al. (2014) Reef-scale thermal stress
monitoring of coral ecosystems: new 5-km global products from NOAA Coral
Reef Watch. Remote Sensing 6:11579–11606.</p>
<p>Skirving WJ, Heron SF, Marsh BL, et al. (2019) The relentless march
of mass coral bleaching: a global perspective of changing heat stress.
Coral Reefs 38:547–557.</p>
<p>Wyatt ASJ, Leichter JJ, Toth LT, et al. (2023) Hidden heatwaves and
severe coral bleaching linked to mesoscale eddies and thermocline
dynamics. Nature Communications 14:25.</p>
<hr />
<h2 id="figure-legends">Figure Legends</h2>
<p><strong>Figure 1.</strong> Prediction skill comparison. (A) Equitable
Threat Score (ETS) by threshold for CoralTemp SST (blue circles, n=204)
and in-situ loggers (orange squares, n=182). Dashed green line indicates
the global optimum ETS of 0.218 from DeCarlo (2020). Vertical dotted
line marks the optimal threshold of 5 days. (B) Comparison of CoralTemp
SST and in-situ logger performance at the 5-day threshold (n=182),
showing ETS, Probability of Detection (POD), and 1−False Alarm
Ratio.</p>
<hr />
<p><em>Word count: ~3,200 (excluding tables, figures, and
references)</em></p>
</body>
</html>
